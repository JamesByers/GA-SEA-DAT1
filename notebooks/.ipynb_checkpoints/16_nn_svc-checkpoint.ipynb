{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks and Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, linear_model, datasets\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   5., ...,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ...,  10.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ...,  16.,   9.,   0.],\n",
       "       ..., \n",
       "       [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
       "       [  0.,   0.,   2., ...,  12.,   0.,   0.],\n",
       "       [  0.,   0.,  10., ...,  12.,   1.,   0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new dataset, handwritten digits!\n",
    "digits = datasets.load_digits()\n",
    "digits.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1797"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(digits.data)      # 1,797 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(digits.data[0])   # 8 x 8 pixel image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPcAAAD7CAYAAAC2TgIoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e4f61d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digits.images[-5], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "# the number 9\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "digits.target[-5]\n",
    "# 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digits_X, digits_y = digits.data, digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual page for scikit-learn neural network models (unsupervised): http://scikit-learn.org/stable/modules/neural_networks.html#neural-network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rbm = BernoulliRBM(random_state=0)\n",
    "rbm.fit(digits_X, digits_y,)\n",
    "biases_for_visible = rbm.intercept_visible_\n",
    "print biases_for_visible.shape\n",
    "print biases_for_visible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "biases_for_hidden = rbm.intercept_hidden_\n",
    "print biases_for_hidden.shape\n",
    "print biases_for_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = rbm.components_\n",
    "print weights.shape\n",
    "print weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use an unsupervised artifical neural network to ascertain feature\n",
    "rbm = BernoulliRBM(random_state=0)\n",
    "logistic = linear_model.LogisticRegression()\n",
    "classifier = Pipeline(steps=[('rbm', rbm), ('logistic', logistic)])\n",
    "# We can use a pipeline to do two things at once. Use the neural network to find features\n",
    "# and use a logistic regression to classify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_val_score(classifier, digits_X, digits_y, cv=5, scoring='accuracy').mean()\n",
    "# OOF! Not so great..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ok but what if we just use logistic regression without first getting new features?\n",
    "logistic = linear_model.LogisticRegression()\n",
    "cross_val_score(logistic, digits_X, digits_y, cv=5, scoring='accuracy').mean()\n",
    "# OK not bad!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVMs - Support Vector Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual page for scikit-learn SVC: http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's try a SVM classifier\n",
    "clf = svm.SVC()\n",
    "clf.fit(digits_X, digits_y)\n",
    "plt.imshow(digits.images[-5], cmap=plt.cm.gray_r, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.predict(digits.data[-5])\n",
    "# WOOHOO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_val_score(clf, digits_X, digits_y, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "# OOF again, we lost to the logistic regression...\n",
    "# This estimator defaults to the Gaussian (aka radial basis function)\n",
    "# let's try something else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Guassian has two parameters, gamma and C\n",
    "\n",
    "Intuitively, the gamma parameter defines how far the influence of a \n",
    "single training example reaches, with low values meaning ‘far’ and \n",
    "high values meaning ‘close’. \n",
    "\n",
    "* small gamma: The model is constrained, can under-fit!\n",
    "* big gamma: Tries to capture the shape too well: can over-fit!\n",
    "\n",
    "\n",
    "* small C: Makes the decision surface smooth and simple, can under-fit!\n",
    "* big C: Selects more support vectors: can over-fit!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# note the scale of gamma and C\n",
    "clf = svm.SVC(gamma=0.001, C=1)\n",
    "cross_val_score(clf, digits_X, digits_y, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "# Skadoosh!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "iris_X = iris.data[:, :2]  # we only take the first two features. We could\n",
    "                      # avoid this ugly slicing by using a two-dim dataset\n",
    "iris_y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Start with logistic Regression\n",
    "logistic = linear_model.LogisticRegression()\n",
    "cross_val_score(logistic, iris_X, iris_y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's try a SVM\n",
    "clf = svm.SVC()\n",
    "cross_val_score(clf, iris_X, iris_y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compare three SVMs with different kernels\n",
    "\n",
    "* Radial Bias Function (RBF)\n",
    "* Linear\n",
    "* Poly of degree 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C = 1.0  # SVM regularization parameter\n",
    "rbf_svc = svm.SVC(kernel='rbf', gamma=0.7, C=C).fit(iris_X, iris_y)  # default kernel\n",
    "svc = svm.SVC(kernel='linear', C=C).fit(iris_X, iris_y)\n",
    "poly_svc = svm.SVC(kernel='poly', degree=3, C=C).fit(iris_X, iris_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a mesh to plot in\n",
    "x_min, x_max = iris_X[:, 0].min() - 1, iris_X[:, 0].max() + 1\n",
    "y_min, y_max = iris_X[:, 1].min() - 1, iris_X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, .02),\n",
    "                     np.arange(y_min, y_max, .02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# title for the plots\n",
    "titles = ['SVC with linear kernel',\n",
    "          'SVC with RBF kernel',\n",
    "          'SVC with polynomial (degree 3) kernel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 11, 11  # set plot size\n",
    "\n",
    "for i, clf in enumerate((svc, rbf_svc, poly_svc)):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)\n",
    "    # Plot also the training points\n",
    "    plt.scatter(iris_X[:, 0], iris_X[:, 1], c=iris_y, cmap=plt.cm.Paired)\n",
    "    plt.xlabel('Sepal length')\n",
    "    plt.ylabel('Sepal width')\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.title(titles[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'SVC with linear kernel score: ',cross_val_score(svc, iris_X, iris_y, cv=5, scoring='accuracy').mean()\n",
    "print 'SVC with RBF kernel score: ',cross_val_score(rbf_svc, iris_X, iris_y, cv=5, scoring='accuracy').mean()\n",
    "print 'SVC with polynomial (degree 3) kernel score: ',cross_val_score(poly_svc, iris_X, iris_y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets try SVC on some different data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "circles_X, circles_y = make_circles(n_samples=1000, random_state=123, noise=0.1, factor=0.2)\n",
    "cm = cmap=plt.cm.Paired\n",
    "plt.scatter(circles_X[:,0], circles_X[:,1], c=circles_y, cmap=cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use an unsupervised artifical neural network to ascertain feature\n",
    "\n",
    "rbm = BernoulliRBM(random_state=0)\n",
    "logistic = linear_model.LogisticRegression()\n",
    "classifier = Pipeline(steps=[('rbm', rbm), ('logistic', logistic)])\n",
    "# We can use a pipeline to do two things at once. Use the neural network to find features\n",
    "# and use a logistic regression to classify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "circles_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's predict them without graphs\n",
    "logreg = LogisticRegression()\n",
    "cross_val_score(logreg, circles_X, circles_y, cv=5, scoring='accuracy').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel = 'linear')        # I like lines\n",
    "cross_val_score(clf, circles_X, circles_y, cv=5, scoring='accuracy').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel = 'poly', degree = 3)        # I like 3rd degree polys\n",
    "cross_val_score(clf, circles_X, circles_y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel = 'rbf')           # I like circles\n",
    "cross_val_score(clf, circles_X, circles_y, cv=5, scoring='accuracy').mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The radial basis function kernel projects the data into higher dimensions that accompany circles well\n",
    "\n",
    "OK now with graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg.fit(circles_X, circles_y)\n",
    "C = 1.0  # SVM regularization parameter\n",
    "rbf_svc = svm.SVC(kernel='rbf', gamma=0.7, C=C).fit(circles_X, circles_y)  # default kernel\n",
    "svc = svm.SVC(kernel='linear', C=C).fit(circles_X, circles_y)\n",
    "poly_svc = svm.SVC(kernel='poly', degree=3, C=C).fit(circles_X, circles_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a mesh to plot in\n",
    "x_min, x_max = circles_X[:, 0].min() - 1, circles_X[:, 0].max() + 1\n",
    "y_min, y_max = circles_X[:, 1].min() - 1, circles_X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, .02),\n",
    "                     np.arange(y_min, y_max, .02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# title for the plots\n",
    "titles = ['Logistic Regression ',\n",
    "          'SVC with linear kernel',\n",
    "          'SVC with polynomial (degree 3) kernel',\n",
    "          'SVC with RBF kernel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print 'Logistic Regression score: ',cross_val_score(logreg, circles_X, circles_y, cv=5, scoring='accuracy').mean()\n",
    "print 'SVC with linear kernel score: ',cross_val_score(svc, circles_X, circles_y, cv=5, scoring='accuracy').mean()\n",
    "print 'SVC with polynomial (degree 3) kernel score: ',cross_val_score(poly_svc, circles_X, circles_y, cv=5, scoring='accuracy').mean()\n",
    "print 'SVC with RBF kernel score: ',cross_val_score(rbf_svc, circles_X, circles_y, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "\n",
    "for i, clf in enumerate((logreg, svc, poly_svc, rbf_svc)):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)\n",
    "    # Plot also the training points\n",
    "    plt.scatter(circles_X[:, 0], circles_X[:, 1], c=circles_y, cmap=plt.cm.Paired)\n",
    "    plt.xlabel('Sepal length')\n",
    "    plt.ylabel('Sepal width')\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.title(titles[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a real thing of beauty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<pr>\n",
    "### Bonus: Visua\n",
    "\n",
    "Intuitively, the gamma parameter defines how far the influence of a \n",
    "single training example reaches, with low values meaning ‘far’ and \n",
    "high values meaning ‘close’. \n",
    "\n",
    "* small gamma: The model is constrained, can under-fit!\n",
    "* big gamma: Tries to capture the shape too well: can over-fit!\n",
    "\n",
    "\n",
    "* small C: Makes the decision surface smooth and simple, can under-fit!\n",
    "* big C: Selects more support vectors: can over-fit!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualizing different C\n",
    "\n",
    "X = np.r_[np.random.randn(20, 2) - [2, 2], np.random.randn(20, 2) + [2, 2]]\n",
    "Y = [0] * 20 + [1] * 20\n",
    "\n",
    "# figure number\n",
    "fignum = 1\n",
    "\n",
    "# fit the model\n",
    "for name, penalty in (('C of 1', 1), ('C of 0.05', 0.05)):\n",
    "\n",
    "    clf = svm.SVC(kernel='linear', C=penalty)\n",
    "    clf.fit(X, Y)\n",
    "\n",
    "    # get the separating hyperplane\n",
    "    w = clf.coef_[0]\n",
    "    a = -w[0] / w[1]\n",
    "    xx = np.linspace(-5, 5)\n",
    "    yy = a * xx - (clf.intercept_[0]) / w[1]\n",
    "\n",
    "    # plot the parallels to the separating hyperplane that pass through the\n",
    "    # support vectors\n",
    "    margin = 1 / np.sqrt(np.sum(clf.coef_ ** 2))\n",
    "    yy_down = yy + a * margin\n",
    "    yy_up = yy - a * margin\n",
    "\n",
    "    # plot the line, the points, and the nearest vectors to the plane\n",
    "    plt.figure(fignum, figsize=(4, 3))\n",
    "    plt.clf()\n",
    "    plt.plot(xx, yy, 'k-')\n",
    "    plt.plot(xx, yy_down, 'k--')\n",
    "    plt.plot(xx, yy_up, 'k--')\n",
    "\n",
    "    plt.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=80,\n",
    "                facecolors='none', zorder=10)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=Y, zorder=10, cmap=plt.cm.Paired)\n",
    "\n",
    "    plt.axis('tight')\n",
    "    plt.title(name)\n",
    "\n",
    "    XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]\n",
    "    Z = clf.predict(np.c_[XX.ravel(), YY.ravel()])\n",
    "\n",
    "    fignum = fignum + 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "* small C: can under-fit!\n",
    "* big C: can over-fit!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
